{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7405624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This file search the google web based on search term provided and scraps 99 websites from the web.\\n\\nVery Important:\\n    1) Make sure to execute the required libraries by either commenting/uncommenting pip\\n    2) Make sure to use the right API Key for the GOOGLE_CS_API_KEY variable.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" This file search the google web based on search term provided and scraps 99 websites from the web.\n",
    "\n",
    "Very Important:\n",
    "    1) Make sure to execute the required libraries by either commenting/uncommenting pip\n",
    "    2) Make sure to use the right API Key for the GOOGLE_CS_API_KEY variable.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0457a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r \"/home/ec2-user/SageMaker/AscendNotebook/ascendrequirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097ec17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os module for interacting with the operating system\n",
    "import os\n",
    "\n",
    "# Import pandas as pd for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "from TimeMethods import get_Date, get_DateTime, Time\n",
    "\n",
    "from WebScraping import (search_term_directory, crawl_search_term, scrap_websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ba2d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory \"/home/ec2-user/SageMaker/AscendNB/WebScrapingCode\".\n",
      "Root directory \"/home/ec2-user/SageMaker/AscendNB/\".\n",
      "Directory to save scraping execution results \"/home/ec2-user/SageMaker/AscendNB/CodeExecutionMetrics/\".\n",
      "Directory to save scraped data files \"/home/ec2-user/SageMaker/AscendNB/WebScrapedUpdatedApproach/\".\n",
      "Search Results from country: countryAR\n"
     ]
    }
   ],
   "source": [
    "# Define the following NUM_RESULTS variable to determine the number of web search results to crawl for scrapping\n",
    "NUM_RESULTS = 500\n",
    "\n",
    "# Exclude Wikipedia, Reddit, and LinkedIn from search results\n",
    "# exclude_sites = 'site:en.wikipedia.org OR site:reddit.com OR site:linkedin.com'\n",
    "\n",
    "MY_API_KEY = 'XXXXXXXX' # This Sai Vinnakota personal Google API keys\n",
    "# TIOT_API_KEY = 'XXXXXXXX' #'XXXXXXXX' # This is TensorIOT Google API Keys\n",
    "MY_CSE_ID = 'XXXXXXXX' #'XXXXXXXX' # Replace this with the client Search Engine ID\n",
    "GOOGLE_CS_API_KEY = MY_API_KEY\n",
    "\n",
    "# Get the working directory\n",
    "wrk_dir = os.getcwd()\n",
    "print(f\"Current working directory \\\"{wrk_dir}\\\".\")\n",
    "\n",
    "# Initialize Root Directory\n",
    "ROOT_DIR = \"/home/ec2-user/SageMaker/AscendNB/\"\n",
    "print(f\"Root directory \\\"{ROOT_DIR}\\\".\")\n",
    "\n",
    "# Initialize directory to save operation execution results\n",
    "Rslts_Save_Dir = \"/home/ec2-user/SageMaker/AscendNB/CodeExecutionMetrics/\"\n",
    "print(f\"Directory to save scraping execution results \\\"{Rslts_Save_Dir}\\\".\")\n",
    "\n",
    "# Initialize directory to save web scraped data\n",
    "WebSC_DIR = \"/home/ec2-user/SageMaker/AscendNB/WebScrapedUpdatedApproach/\"\n",
    "print(f\"Directory to save scraped data files \\\"{WebSC_DIR}\\\".\")\n",
    "\n",
    "country_nm = 'countryAR'\n",
    "print(f\"Search Results from country: {country_nm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95debe06",
   "metadata": {},
   "source": [
    "# Use the right Google Custom Search API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1479a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CS_API_KEY = MY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc4baf",
   "metadata": {},
   "source": [
    "# Chose the appropriate search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842fb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MY_SEARCH = \"Nylon & Polyamide injection molders\"\n",
    "# MY_SEARCH = \"Plastic Profile Extruders\"\n",
    "# MY_SEARCH = \"Plastic Sheet extruders\"\n",
    "# MY_SEARCH = \"Recycled carpet fibers applications\"\n",
    "MY_SEARCH = \"Nylon Compounders & Polyamide Compounders\"\n",
    "\n",
    "# MY_SEARCHES = [\"Nylon & Polyamide injection molders\", \"Plastic Profile Extruders\", \"Plastic Sheet extruders\", \"Recycled carpet fibers applications\", \"Nylon Compounders & Polyamide Compounders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e50ea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Google search for \"Nylon Compounders & Polyamide Compounders\".\n",
      "================================================================\n",
      " \n",
      "--> Search Term directory that will be used to save results is: \"Nylon_Compounders_Polyamide_Compounders\".\n",
      "--> Starting Crawling for Nylon Compounders & Polyamide Compounders term at: 2024-06-21 05:07:42\n",
      "--> Finished Crawling for Nylon Compounders & Polyamide Compounders term at: 2024-06-21 05:07:42\n",
      " \n",
      "Completed web crawling and started web scrapping.\n",
      " \n",
      "--> Current Working Directory: /home/ec2-user/SageMaker/AscendNB/WebScrapingCode\n",
      "Directory 'Nylon_Compounders_Polyamide_Compounders' already exists.\n",
      "URL counter to scrap data:  1\n",
      "Title: Principles of Polymer Processing\n",
      "Snippet: ... polymer products. Thus, the focus of future polymer processing science will ... Nylon. W . H. Carothers. 1935. At the. DuP ont. Laboratories. Low density.\n",
      "Company URL: http://www3.fi.mdp.edu.ar\n",
      "Company Name: Www3\n",
      "Original URL: http://www3.fi.mdp.edu.ar/procesamiento1/material/Tadmor-Gogos.pdf\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is Tadmor-Gogos.pdf\n",
      "URL counter to scrap data:  2\n",
      "Title: Creep behaviour of injection moulded polyamide 6/organoclay ...\n",
      "Snippet: In par- ticular, Polyamide 6 (or Nylon 6) is widely used in the automotive ... Nylon 6 nanocomposites by melt compounding. Polymer. 2001;42(3):1083–94. [6] ...\n",
      "Company URL: https://ri.conicet.gov.ar\n",
      "Company Name: Ri\n",
      "Original URL: https://ri.conicet.gov.ar/bitstream/handle/11336/6296/CONICET_Digital_Nro.8232_A.pdf?sequence=2\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is CONICET_Digital_Nro.8232_A.pdf?sequence=2\n",
      "URL counter to scrap data:  3\n",
      "Title: SEALS AND SEALING HANDBOOK\n",
      "Snippet: ... nylon, virgin PTFE, filled PTFE and, for higher temperature and pressure ... polyamide, aromatic polyamide (aramid) and other fibres bonded with elastomer ...\n",
      "Company URL: http://users.df.uba.ar\n",
      "Company Name: Users\n",
      "Original URL: http://users.df.uba.ar/cobelli/Taller_de_Mecanizado/Guias_para_diseno_de_piezas/Sellos_y_Sellado/Seals_and_sealing_Handbook.pdf\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is Seals_and_sealing_Handbook.pdf\n",
      "URL counter to scrap data:  4\n",
      "Title: Effect of hygrothermal ageing on morphology and indentation ...\n",
      "Snippet: The effect of water immersion on the morphology and indentation modulus of injection moulded nylon 6 and its organoclay nanocomposites was investigated.\n",
      "Company URL: https://ri.conicet.gov.ar\n",
      "Company Name: Ri\n",
      "Original URL: https://ri.conicet.gov.ar/bitstream/handle/11336/34938/CONICET_Digital_Nro.a9390f05-c149-4265-9a08-2db727cf6cb6_A.pdf?sequence=2\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is CONICET_Digital_Nro.a9390f05-c149-4265-9a08-2db727cf6cb6_A.pdf?sequence=2\n",
      "URL counter to scrap data:  5\n",
      "Title: Review of Mechanical Properties, Migration, and Potential ...\n",
      "Snippet: polyamide 6/silver-nano- and microcomposites. Mater Chem Phys. 108(1):61–6 ... nylon 1012/clay nanocomposite. J Appl Polym Sci 83(11):2403–10. C 2015 ...\n",
      "Company URL: http://www.innocua.net\n",
      "Company Name: Innocua\n",
      "Original URL: http://www.innocua.net/web/download-3102/crf312139.pdf\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is crf312139.pdf\n",
      "URL counter to scrap data:  6\n",
      "Title: PRIMERA REUNION INTERNACIONAL DE CIENCIAS ...\n",
      "Snippet: Polyamide membranes Millipore were placed in filter holder and 10mL of ... µm nylon filters before use. The detection was accomplished at 224 nm. Solutions ...\n",
      "Company URL: http://ricifa.com.ar\n",
      "Company Name: Ricifa\n",
      "Original URL: http://ricifa.com.ar/wp-content/uploads/2021/09/Resumenes-2010.pdf\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is Resumenes-2010.pdf\n",
      "URL counter to scrap data:  7\n",
      "Title: Curriculum Vitae Patricia María Frontini\n",
      "Snippet: ... Polyamide 6 In Impact” by E. Lievana, C. Bernal, P. Frontini for publication ... moulded nylon 6/organoclay nanocomposites”.-Rocio Seltzer, Patricia M.\n",
      "Company URL: https://www.ancefn.org.ar\n",
      "Company Name: Ancefn\n",
      "Original URL: https://www.ancefn.org.ar/user/FILES/PREMIOS/2019/CV%20P.%20Frontini.pdf\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is CV%20P.%20Frontini.pdf\n",
      "URL counter to scrap data:  8\n",
      "Title: Departamento de Matematica - english3\n",
      "Snippet: Nov 23, 2017 ... ... compounders compounding compounds comprador compradore compradores ... nylon nylons nym nyman nymph nymphae nymphaea nymphaeaceae ...\n",
      "Company URL: http://cms.dm.uba.ar\n",
      "Company Name: Cms\n",
      "Original URL: http://cms.dm.uba.ar/academico/materias/2docuat2017/investigacion_operativa/2017/english3.txt/view\n",
      "The text does not contain '.pdf'. Therefore extracting data from URL\n",
      "Can fetch full content.\n",
      "\n",
      " \n",
      "URL counter to scrap data:  9\n",
      "Title: CARACTERIZACIÓN MATERIAL COMPUESTO PET-VIDRIO.-\n",
      "Snippet: El nylon se convirtió en una de las fuentes principales de fibras textiles ... compounds with fibre lengths u 7,5 mm prior to processing. The method is not ...\n",
      "Company URL: https://rdu.unc.edu.ar\n",
      "Company Name: Rdu\n",
      "Original URL: https://rdu.unc.edu.ar/bitstream/11086/1839/1/PI%20SANTAMARINA.-.pdf\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is PI%20SANTAMARINA.-.pdf\n",
      "URL counter to scrap data:  10\n",
      "Title: Noticiero del Plástico (Elastómeros + Moldes y Matrices con Guía - P ...\n",
      "Snippet: es ese que te acompaña en todo proceso, creando más de 600 matrices personalizadas que se adaptan al diseño y necesidad de tu negocio.\n",
      "Company URL: http://www.emmafiorentino.com\n",
      "Company Name: Emmafiorentino\n",
      "Original URL: http://www.emmafiorentino.com/biblioteca/2020/noti/65.pdf\n",
      "The text contains '.pdf'.\n",
      "The pdf file name is 65.pdf\n",
      "--> Current Working Directory: /home/ec2-user/SageMaker/AscendNB/WebScrapingCode\n",
      "Completed web scrapping.\n",
      " \n",
      "--> Current Working Directory: /home/ec2-user/SageMaker/AscendNB/WebScrapingCode\n",
      "================================================================\n",
      " \n"
     ]
    }
   ],
   "source": [
    "Crawl_scrap_processing_status = pd.DataFrame(columns = ['Search Term','Number of Results Crawled', 'Crawl Start Time', \n",
    "                                           'Crawl End Time', 'Crawl Exec Time in Minutes'])\n",
    "\n",
    "print(f\"Performing Google search for \\\"{MY_SEARCH}\\\".\")\n",
    "print(\"================================================================\")\n",
    "print(\" \")\n",
    "\n",
    "# Define search term directory to save web scrapping results\n",
    "SEARCH_TERM_DIR = search_term_directory(MY_SEARCH)\n",
    "\n",
    "print(f\"--> Search Term directory that will be used to save results is: \\\"{SEARCH_TERM_DIR}\\\".\")\n",
    "\n",
    "# Crawl the web to get results\n",
    "Crawl_process_stats, results = crawl_search_term(MY_SEARCH, GOOGLE_CS_API_KEY, MY_CSE_ID, NUM_RESULTS, country_nm)\n",
    "\n",
    "print(\"Completed web crawling and started web scrapping.\")\n",
    "print(\" \")\n",
    "\n",
    "Metadata_DF_Final = scrap_websites(results, MY_SEARCH, WebSC_DIR, SEARCH_TERM_DIR, wrk_dir, get_Date(), country_nm)\n",
    "\n",
    "print(\"Completed web scrapping.\")\n",
    "print(\" \")\n",
    "\n",
    "# Saving search results summary to a csv file\n",
    "print(\"--> Current Working Directory:\", os.getcwd())\n",
    "Metadata_DF_Final.to_csv(Rslts_Save_Dir + \"/\" + SEARCH_TERM_DIR +\"_\"+ get_DateTime() + '.csv', index=False)\n",
    "\n",
    "print(\"================================================================\")\n",
    "print(\" \")\n",
    "\n",
    "# Append the row\n",
    "Crawl_scrap_processing_status.loc[len(Crawl_scrap_processing_status)] = Crawl_process_stats\n",
    "\n",
    "Crawl_scrap_processing_status.to_csv(Rslts_Save_Dir + \"/\" + MY_SEARCH +\"WebScrap_ProcessTime_\"+ get_DateTime() + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05080e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb0e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
