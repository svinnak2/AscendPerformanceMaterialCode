{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14123893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install boto3 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc92e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ragas==0.0.20 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b776265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r \"/home/ec2-user/SageMaker/AscendNotebook/ascendrequirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb49701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "# from IPython.core.display import HTML\n",
    "# HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e781d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session Session(region_name='us-east-1')\n",
      "AWS Region Name: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# import RetrieveNGenerate\n",
    "\n",
    "from RetrieveNGenerate import RetrieveAndGenerate as RAG\n",
    "\n",
    "# Import the os module for interacting with the operating system\n",
    "import os\n",
    "\n",
    "# Import the boto3 library for interacting with AWS services\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the datetime class from the datetime module to handle date and time objects\n",
    "from datetime import datetime\n",
    "\n",
    "# Importing the time module to handle time-related functions\n",
    "import time\n",
    "\n",
    "from langfuse import Langfuse\n",
    "\n",
    "#import metrics\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall\n",
    ")\n",
    "\n",
    "from ragas.llms import LangchainLLM\n",
    "\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd88989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session Session(region_name='us-east-1')\n",
      "AWS Region Name: us-east-1\n"
     ]
    }
   ],
   "source": [
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\" # try with both claude instant as well as claude-v2. for claude v2 - \"anthropic.claude-v2\"\n",
    "MDL_TYPE = 'ANTH_CLAUDE_Haiku_'\n",
    "kb_id = \"EJBFFIJDIJ\"\n",
    "\n",
    "# get keys for your project from https://cloud.langfuse.com\n",
    "LANGFUSE_PUBLIC_KEY = \"XXXXXXXXXXX\" #replace it with your public key\n",
    "LANGFUSE_SECRET_KEY = \"XXXXXXXXXXX\" #replace it with you secret key\n",
    "LANGFUSE_HOST=\"https://us.cloud.langfuse.com\"\n",
    "\n",
    "MX_TKN = 4000\n",
    "TMPRT = 0.1\n",
    "TOP_P = 0.5\n",
    "TOP_K = 1\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "model_kwargs_claude = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_k\": 0,\n",
    "    \"max_tokens\": 4000\n",
    "}\n",
    "\n",
    "llm_for_text_generation = ChatBedrock(model_id=model_id,\n",
    "              model_kwargs=model_kwargs_claude,\n",
    "              streaming=True,\n",
    "              client = bedrock_client,)\n",
    "\n",
    "\n",
    "llm_for_evaluation = ChatBedrock(model_id=model_id,\n",
    "              model_kwargs=model_kwargs_claude,\n",
    "              streaming=True,\n",
    "              client = bedrock_client,)\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",client=bedrock_client)\n",
    "\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "\n",
    "print(\"session\", boto3_session)\n",
    "print(\"AWS Region Name:\", region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389b2354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present working directory: /home/ec2-user/SageMaker/AscendNotebook/Testing_RAG_LLMs\n",
      "Directory to save results: /home/ec2-user/SageMaker/AscendNotebook/CodeExecutionMetrics/\n"
     ]
    }
   ],
   "source": [
    "# The directory to save results\n",
    "Rslts_Save_Dir = \"/home/ec2-user/SageMaker/AscendNotebook/CodeExecutionMetrics/\"\n",
    "\n",
    "print(\"Present working directory:\", os.getenv('PWD'))\n",
    "print(\"Directory to save results:\", Rslts_Save_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd175d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=kb_id,\n",
    "        retrieval_config={\"vectorSearchConfiguration\": {\"numberOfResults\": 4}},\n",
    "        # endpoint_url=endpoint_url,\n",
    "        # region_name=\"us-east-1\",\n",
    "        # credentials_profile_name=\"<profile_name>\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0282b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "    You are the best customer acquisition data analyst and strategist, you provide answers to questions by using fact based and statistical information when possible. \n",
    "    Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags. \n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "    Assistant:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=kb_id,\n",
    "        retrieval_config={\"vectorSearchConfiguration\": {\"numberOfResults\": 4}},\n",
    "        # endpoint_url=endpoint_url,\n",
    "        # region_name=\"us-east-1\",\n",
    "        # credentials_profile_name=\"<profile_name>\",\n",
    "    )\n",
    "\n",
    "# Setup RAG pipeline\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm_for_text_generation\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb5fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"What products use nylon?\", \n",
    "\"give me a list of top 100 products that use nylon (10 is too small and is no representative)?\", \n",
    "\"what companies use Nylon in their products?\", \n",
    "\"who are the biggest users of nylon?\", \n",
    "\"who is compounding Nylon in North America and South America or Latin America?\", \n",
    "\"Are compounders using more recycled feedstock?\", \n",
    "\"What innovations are driving the use of recycled polypropylene?\", \n",
    "\"What are the main applications of recycled PP in the automotive industry?\", \n",
    "\"Which brands are known for their use of recycled PP in their products?\", \n",
    "\"What are some examples of high-volume products produced by leading companies using injection molding?\", \n",
    "\"How do aerospace companies utilize nylon 6,6 in their components?\", \n",
    "\"List all the companies extruding Nylon for extruded profiles and sheet?\", \n",
    "\"Which automotive companies are innovating with nylon 6,6 to enhance vehicle performance?\", \n",
    "\"In the automotive sector, what are the key components produced using nylon 6,6, and which manufacturers specialize in their production?\", \n",
    "\"What are the major industrial machinery components manufactured from nylon 6,6, and which companies are the leading suppliers of these components?\", \n",
    "\"Which consumer electronics companies rely on nylon 6,6 for the production of their casings and structural components, and how much nylon 6,6 do they consume annually?\", \n",
    "\"Can you list the flagship consumer electronic devices that feature nylon 6,6 components, and identify the manufacturers responsible for their production?\", \n",
    "\"In the automotive sector, what are the critical components manufactured from nylon 6,6, and which suppliers specialize in the production of these components?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d1d15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = [\"Give me a list of 100 Injection Molders company names by injection molding sales and rank?\",\n",
    "#             \"Give me the list of TOP Profile Extruders companies?\",\n",
    "#             \"Give me the list of TOP THERMOFORMERS companies?\",\n",
    "#             \"Give me a list of top 5 Injection Molders and their molding sales in $?\"]\n",
    "\n",
    "\n",
    "# questions = [\"What products use nylon?\", \n",
    "# \"give me a list of top 100 products that use nylon (10 is too small and is no representative)?\", \n",
    "# \"what companies use Nylon in their products?\", \n",
    "# \"who are the biggest users of nylon?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0fda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"Give me a list of 100 Injection Molders company names by injection molding sales and rank?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7021f07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check connection to Langfuse: True\n"
     ]
    }
   ],
   "source": [
    "langfuse = Langfuse(public_key=LANGFUSE_PUBLIC_KEY,secret_key=LANGFUSE_SECRET_KEY, host = LANGFUSE_HOST)\n",
    "print(\"Check connection to Langfuse:\", langfuse.auth_check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ff75af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_bedrock_model = LangchainLLM(llm_for_evaluation)\n",
    "\n",
    "#set embeddings model for evaluating answer relevancy metric\n",
    "answer_relevancy.embeddings = bedrock_embeddings\n",
    "\n",
    "metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy\n",
    "    ]\n",
    "\n",
    "for m in metrics:\n",
    "    m.__setattr__(\"llm\", ragas_bedrock_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4c0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_with_ragas(query, chunks, answer):\n",
    "    scores = {}\n",
    "    for m in metrics:\n",
    "#         print(f\"calculating {m.name}\")\n",
    "        scores[m.name] = m.score_single(\n",
    "            {\"question\": query, \"contexts\": chunks, \"answer\": answer}\n",
    "        )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "929ef8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 1\n",
    "# Q_A_DF = pd.DataFrame(columns = ['Question_Num', 'Question', 'Answer', 'Answer_Relevancy', 'faithfulness', 'context_sources', 'Contexts'])\n",
    "# for query in questions:\n",
    "#     Q_Num = \"Question - \" + str(counter)\n",
    "#     print(\"question number:\", Q_Num)\n",
    "#     print(\"Question being processed: \",query)\n",
    "\n",
    "#     question = query\n",
    "#     Ans = \"Answer - \" + str(counter)\n",
    "#     trace = langfuse.trace(name=\"RAG_W_512_Chunk\", user_id = \"Sai_Test\", tags=[\"EXP 06/15/2024\", Q_Num])\n",
    "#     contexts = [docs.page_content for docs in retriever.get_relevant_documents(query)]\n",
    "#     trace.span(name=\"retrieval\", \n",
    "#                input={\"question\": question}, \n",
    "#                output={\"contexts\": contexts},\n",
    "#         )\n",
    "    \n",
    "#     # Reterieve and Generate response based on question, model_type, temperature, etc.\n",
    "#     response = RAG(TMPRT, MX_TKN, TOP_K, TOP_P, question, kb_id, region_name, '', model_id)\n",
    "#     print(response)\n",
    "\n",
    "#     # Used Context for Generating Answers\n",
    "#     contxt = [reference['content']['text'] for citation in response['citations'] for reference in citation['retrievedReferences']]\n",
    "\n",
    "#     # Generated Answers\n",
    "#     generated_answer = response[\"output\"][\"text\"]\n",
    "\n",
    "#     # Context Source\n",
    "#     context_source = [reference['location']['s3Location']['uri'] for citation in response['citations'] for reference in citation['retrievedReferences']]\n",
    "\n",
    "# #     print(generated_answer)\n",
    "# #     print(\" \")\n",
    "\n",
    "#     trace.span(\n",
    "#             name=\"generation\",\n",
    "#             input={\"question\": question, \"contexts\": contxt, \"Context_Source\": context_source},\n",
    "#             output={\"answer\": generated_answer}\n",
    "#         )\n",
    "    \n",
    "#     # compute scores for the question, context, answer tuple\n",
    "#     ragas_scores = score_with_ragas(question, contxt, generated_answer)\n",
    "#     ragas_scores\n",
    "#     for m in metrics:\n",
    "#         trace.score(name=m.name, value=ragas_scores[m.name])\n",
    "    \n",
    "#     new_row = {'Question_Num': Q_Num, 'Question': query, 'Answer': generated_answer, 'Answer_Relevancy':ragas_scores['answer_relevancy'],\n",
    "#               'faithfulness': ragas_scores['faithfulness'], 'context_sources': context_source, 'Contexts': contxt}\n",
    "#     Q_A_DF.loc[len(Q_A_DF)] = new_row\n",
    "    \n",
    "#     counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "807ba0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbs_dict = { \n",
    "    'kb1': { 'Chunk_Size': '900', 'kb_id': 'EJBFFIJDIJ', 'kb_name': 'Knowledge base name'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcff3c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Knowledge ID: EJBFFIJDIJ to process duestions\n",
      "=================================================\n",
      "question number: Question - 1\n",
      "Question being processed:  What products use nylon?\n",
      " \n",
      "question number: Question - 2\n",
      "Question being processed:  give me a list of top 100 products that use nylon (10 is too small and is no representative)?\n",
      " \n",
      "question number: Question - 3\n",
      "Question being processed:  what companies use Nylon in their products?\n",
      " \n",
      "question number: Question - 4\n",
      "Question being processed:  who are the biggest users of nylon?\n",
      " \n",
      "question number: Question - 5\n",
      "Question being processed:  who is compounding Nylon in North America and South America or Latin America?\n",
      " \n",
      "question number: Question - 6\n",
      "Question being processed:  Are compounders using more recycled feedstock?\n",
      " \n",
      "question number: Question - 7\n",
      "Question being processed:  What innovations are driving the use of recycled polypropylene?\n",
      " \n",
      "question number: Question - 8\n",
      "Question being processed:  What are the main applications of recycled PP in the automotive industry?\n",
      " \n",
      "question number: Question - 9\n",
      "Question being processed:  Which brands are known for their use of recycled PP in their products?\n",
      " \n",
      "question number: Question - 10\n",
      "Question being processed:  What are some examples of high-volume products produced by leading companies using injection molding?\n",
      " \n",
      "question number: Question - 11\n",
      "Question being processed:  How do aerospace companies utilize nylon 6,6 in their components?\n",
      " \n",
      "question number: Question - 12\n",
      "Question being processed:  List all the companies extruding Nylon for extruded profiles and sheet?\n",
      " \n",
      "question number: Question - 13\n",
      "Question being processed:  Which automotive companies are innovating with nylon 6,6 to enhance vehicle performance?\n",
      " \n",
      "question number: Question - 14\n",
      "Question being processed:  In the automotive sector, what are the key components produced using nylon 6,6, and which manufacturers specialize in their production?\n",
      " \n",
      "question number: Question - 15\n",
      "Question being processed:  What are the major industrial machinery components manufactured from nylon 6,6, and which companies are the leading suppliers of these components?\n",
      " \n",
      "question number: Question - 16\n",
      "Question being processed:  Which consumer electronics companies rely on nylon 6,6 for the production of their casings and structural components, and how much nylon 6,6 do they consume annually?\n",
      " \n",
      "question number: Question - 17\n",
      "Question being processed:  Can you list the flagship consumer electronic devices that feature nylon 6,6 components, and identify the manufacturers responsible for their production?\n",
      " \n",
      "question number: Question - 18\n",
      "Question being processed:  In the automotive sector, what are the critical components manufactured from nylon 6,6, and which suppliers specialize in the production of these components?\n",
      " \n"
     ]
    }
   ],
   "source": [
    "KB_DF = pd.DataFrame(columns = ['Knowledge Base Name', 'Knowledge Base ID', 'Processed Date', 'Processing Time in minutes'])\n",
    "for key, value in kbs_dict.items():\n",
    "#     print(value['Chunk_Size'], value['kb_id'], value['kb_name'])\n",
    "    kb_id = value['kb_id']\n",
    "    Chunk_Size = value['Chunk_Size']\n",
    "    kb_name = value['kb_name']\n",
    "    Chnk_Size = \"Chunk_Size: \" + str(Chunk_Size)\n",
    "    Max_Tokens = \"Max_Tokens: \" + str(MX_TKN)\n",
    "    Temperature_var = \"Temparature: \" + str(TMPRT)\n",
    "    TOP_P_var = \"Top_P: \" + str(TOP_P)\n",
    "    TOP_K_var = 'Top_K: ' + str(TOP_K)\n",
    "    \n",
    "    print(f\"Using Knowledge ID: {kb_id} to process duestions\")\n",
    "    print(\"=================================================\")\n",
    "    \n",
    "    kb_start_time = time.time()\n",
    "    counter = 1\n",
    "    Q_A_DF = pd.DataFrame(columns = ['Question_Num', 'Question', 'Answer', 'Answer_Relevancy', 'faithfulness', 'context_sources', 'Contexts'])\n",
    "    for query in questions:\n",
    "        Q_Num = \"Question - \" + str(counter)\n",
    "        print(\"question number:\", Q_Num)\n",
    "        print(\"Question being processed: \", query)\n",
    "\n",
    "        question = query\n",
    "        Ans = \"Answer - \" + str(counter)\n",
    "        trace = langfuse.trace(name = kb_name, user_id = \"APM_Client\", \n",
    "                               tags = [Q_Num, Chnk_Size, Max_Tokens, Temperature_var, TOP_P_var, TOP_K_var])\n",
    "        contexts = [docs.page_content for docs in retriever.get_relevant_documents(query)]\n",
    "        trace.span(name=\"retrieval\", \n",
    "                   input={\"question\": question}, \n",
    "                   output={\"contexts\": contexts},\n",
    "            )\n",
    "\n",
    "        # Reterieve and Generate response based on question, model_type, temperature, etc.\n",
    "        response = RAG(TMPRT, MX_TKN, TOP_K, question, kb_id, region_name, '', model_id)\n",
    "#         print(response)\n",
    "\n",
    "        # Used Context for Generating Answers\n",
    "        contxt = [reference['content']['text'] for citation in response['citations'] for reference in citation['retrievedReferences']]\n",
    "\n",
    "        # Generated Answers\n",
    "        generated_answer = response[\"output\"][\"text\"]\n",
    "\n",
    "        # Context Source\n",
    "        context_source = [reference['location']['s3Location']['uri'] for citation in response['citations'] for reference in citation['retrievedReferences']]\n",
    "\n",
    "    #     print(generated_answer)\n",
    "    #     print(\" \")\n",
    "\n",
    "        trace.span(\n",
    "                name=\"generation\",\n",
    "                input={\"question\": question, \"contexts\": contxt, \"Context_Source\": context_source,\n",
    "                      \"Max_Tokens\": MX_TKN, 'Temperature': TMPRT, 'Top_P': TOP_P, 'Top_K': TOP_K},\n",
    "                output={\"answer\": generated_answer}\n",
    "            )\n",
    "\n",
    "        # compute scores for the question, context, answer tuple\n",
    "#         ragas_scores = score_with_ragas(question, contxt, generated_answer)\n",
    "#         ragas_scores\n",
    "#         for m in metrics:\n",
    "#             trace.score(name=m.name, value=ragas_scores[m.name])\n",
    "\n",
    "        q_a_new_row = {'Question_Num': Q_Num, 'Question': query, 'Answer': generated_answer, \n",
    "                       'context_sources': context_source, 'Contexts': contxt}\n",
    "        Q_A_DF.loc[len(Q_A_DF)] = q_a_new_row\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "        Q_A_DF.to_csv(Rslts_Save_Dir + kb_name + '_'+ MDL_TYPE + datetime.now().strftime(\"%Y_%m_%d\") + '.csv', index=False)\n",
    "        print(\" \")\n",
    "    \n",
    "    todays_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "    kb_end_time = time.time()\n",
    "    exec_time = (kb_end_time - kb_start_time)/60\n",
    "    \n",
    "    kb_new_row = {'Knowledge Base Name': kb_name, 'Knowledge Base ID': kb_id, \n",
    "                  'Processed Date': todays_date, 'Processing Time in minutes': exec_time}\n",
    "    KB_DF.loc[len(KB_DF)] = kb_new_row\n",
    "    KB_DF.to_csv(Rslts_Save_Dir + \"Chunk_Eval_Results\" + '_'+ MDL_TYPE + datetime.now().strftime(\"%Y_%m_%d\") + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc469f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
